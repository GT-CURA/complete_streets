# Manual Annotation Tool

## üìç Objective
When using automated tool, you will find cases where computer vision model fails to detect sidewalk edges correctly. This might be attributed to the situations when sidewalk is too close or far away from the camera, captures image in wrong perspecitve, occlusion issue, sidewalk appears to look similar roadway or driveway, lighting, shadow or et cetra. Since we do not have a perfect semantic segmentation model that perfectly detects sidewalk pixels or a pipeline addressing those diverse issues... Therefore, we have developed a manual annotation tool to let users directly point out the sidewalk edges and then you will get the estimated width. This tool allows you to
- Mark the sidewalk top and bottom edges of two different images with different pitch angles
- Move the camera image location and loading a new images
- Zoom in or out the imagery 
- Mark No Sidewalk

These features aim to solve issues described above and therefore, you can find out the appropriate sidewalk visible in an imagery and then annotate the edges.

- **Input:** A GeoJSON file of road segment points.  
- **Process:**  
  1. Figures out the points that do not have valid estimated width based on the results generated by an automation tool.
  2. Loads the orignally downloaded images for a given case.
  3. Decide whether there is a need to move the image capture point or zoom in / out the image.
  4. Manually mark the top and bottom edges of the sidewalk visible in an imagery.
- **Output:**  
  - A CSV file for each input point containing the estimated `width` and the point coordinates you marked as the edges. 
  - All newly downloaded images are saved locally in the `/outputs` directory.


## üì¶ Features:
- **`POINT_EPSG4326.geojson`**
  Example input file (5 sample points in Atlanta). Replace with your own points of interest.

- **`manual_collection_env.yml`**  
  Conda environment file specifying dependencies and pinned versions for reproducible setup.
  
- **Python scripts** 
  1. : Filters out the result based on automation tool to find out invalid cases which are needed to be corrected by manual annotation tool
  2. : Generates an interface tool to let you do an annotation task

- **`/manual_collection`**
  Includes guidance and scripts for manual labeling of sidewalk edges.

## üöó Quick Guide
1. **Install conda environment**
   ```bash
   conda env create -f sidewalk_env.yml
   conda activate sidewalk_env
   ```
This envirionemnt only includes~~~

2. Install PyTorch (user-specific) and MMSegmentation
  
  1. Follow the official PyTorch installation instructions for your OS / GPU:

  2. To install MMSegmentation pleaser reference to original guideline by open-mmlab (link)


3. **Set Up the Segmentation Model**
The pipeline uses a configuration and checkpoint from the OpenMMLab MMSegmentation repository. You must clone the repository and download the weights.

  1. Clone the `mmsegmentation` repository
   ```bash
   git clone https://github.com/open-mmlab/mmsegmentation.git
   ```

   2. Create a `checkpoints` directory inside it and download the model:
  ```bash
   # Navigate into the new folder
   cd mmsegmentation
   
   # Create the directory
   mkdir checkpoints
  
   # Download the weights into that directory
   wget -P checkpoints/ https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_8x1_1024x1024_160k_cityscapes/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth
   ```

3. **Prepare input data**
  - Place your road segment GeoJSON file (generated via step1_loader) in the working directory, or use the provided toy dataset for testing.
  - Open `config.py` and edit the following variables:
    - [Line 6] Enter your Google API Key to allow imagery downloads.
    - [Line 10, 11] Verify that these paths correctly point to the files inside the `mmsegmentation` directory you just cloned.
    - [Line 18] Set the path where you want to save all outputs.

   
4. **Run the Python script**
Execute the main script from your terminal. The program will process each link_id from your GeoJSON sequentially.
```bash
python main.py
```

## üîé Descriptions
For details regarding the methodology please find the [paper](https://doi.org/10.1177/23998083251369602).

### References
If you use this model, please cite the following paper: 

```bibtex
@article{your_article,
  title   = {A novel approach for estimating sidewalk width from street view images and computer vision},
  author  = {Lieu, S. J., & Guhathakurta, S.},
  journal = {Environment and Planning B: Urban Analytics and City Science},
  year    = {2025}
}
